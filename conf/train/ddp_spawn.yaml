train_batch_size: 4
eval_batch_size: 8
gradient_acc_steps: 8
gradient_clip_value: 10.0
max_steps: 1200000

apply_early_stopping: True
val_check_interval: 0.5
val_percent_check: 0.1
monitor_var: "val_loss"
monitor_var_mode: "min"
patience: 50
model_name: "default_name"
save_top_k: 3

gpus: 2
precision: 16
amp_level:
training_strategy: "ddp_spawn"

checkpoint_path:

learning_rate: 0.00005
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 0.00000001

seed: 42

dataloader_num_workers: 4
dataloader_pin_memory: True

lr_scheduler: "linear"
warmup_steps: 1000
